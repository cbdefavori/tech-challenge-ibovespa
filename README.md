# Previs√£o do IBOVESPA com Machine Learning

Este projeto foi desenvolvido como parte da **Fase 2 do Tech Challenge** da **P√≥s-Tech FIAP em Data Analytics**. O desafio prop√¥s a aplica√ß√£o pr√°tica de an√°lise de dados e algoritmos de aprendizado de m√°quina para prever a dire√ß√£o do fechamento do √≠ndice **IBOVESPA** (alta ou baixa), com base em dados hist√≥ricos.

---

## Cen√°rio

Assumi o papel de **Cientista de Dados** em um grande fundo de investimentos brasileiro, com a miss√£o de desenvolver um modelo preditivo para apoiar a √°rea de an√°lise quantitativa. A previs√£o alimentaria dashboards internos, orientando decis√µes estrat√©gicas com base na tend√™ncia di√°ria do IBOVESPA.

---

## Objetivo

Construir e avaliar modelos capazes de prever a **tend√™ncia de fechamento do IBOVESPA** para diferentes horizontes de tempo:

- **T+1** (dia seguinte)
- **T+2** (dois dias √† frente)
- **T+5** (cinco dias √† frente)

Foram exploradas diferentes janelas de treino (de 2 a 25 anos), m√∫ltiplas abordagens de modelagem, valida√ß√µes cruzadas temporais, otimiza√ß√µes de hiperpar√¢metros, estrat√©gias de ensemble e ajustes finos de thresholds para tomada de decis√£o mais sens√≠vel.

---

## Estrutura do Projeto

- Aquisi√ß√£o de dados via `yfinance`
- Pr√©-processamento e cria√ß√£o de features (lags, retornos, m√©dias m√≥veis, indicadores t√©cnicos)
- Cria√ß√£o de targets bin√°rios e multiclasse (¬±0.5%)
- Separa√ß√£o temporal entre treino e teste (√∫ltimos 30 dias)
- Testes com diversos algoritmos de Machine Learning
- Ajuste de thresholds (cut-off) para probabilidade de decis√£o
- Compara√ß√£o entre targets T+1, T+2 e T+5

---

## Bibliotecas e Ferramentas Utilizadas

```python
# Manipula√ß√£o de dados
pandas, numpy, calendar, datetime

# Coleta de dados
yfinance

# Modelagem
scikit-learn, xgboost, lightgbm, prophet, tensorflow.keras

# Pr√©-processamento e valida√ß√£o
MinMaxScaler, StandardScaler, TimeSeriesSplit, GridSearchCV, RandomizedSearchCV

# Modelos testados
XGBClassifier, LGBMClassifier, RandomForestClassifier, LogisticRegression, SVC, LSTM, Prophet

# Ensemble
VotingClassifier, StackingClassifier

# Avalia√ß√£o
accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix

# Visualiza√ß√£o
matplotlib, seaborn

# Persist√™ncia de modelos
joblib
```

---

## Modelos Avaliados

- XGBoost (com e sem otimiza√ß√£o)
- LightGBM (com e sem otimiza√ß√£o)
- Random Forest (sem otimiza√ß√£o)
- Regress√£o Log√≠stica
- SVM
- Prophet (executado com binariza√ß√£o)
- LSTM (executado com binariza√ß√£o)
- Ensemble (vota√ß√£o)
- Stacking (XGB + LGBM)

---

## Melhores Resultados

| Target | Modelo                        | Acur√°cia | F1-Score | Observa√ß√µes                                |
|--------|-------------------------------|----------|----------|--------------------------------------------|
| T+1    | ü•á **Random Forest (simples)** | **73.33%** | **63.64%** | Melhor desempenho geral (sem otimiza√ß√£o)   |
| T+1    | LightGBM (sem otimiza√ß√£o)     | 70.00%   | 60.87%   | Forte desempenho explorat√≥rio              |
| T+1    | LightGBM (com otimiza√ß√£o + cutoff 0.4) | 66.67% | 58.33% | Modelo mais balanceado                     |
| T+1    | XGBoost (com otimiza√ß√£o)      | 66.67%   | 50.00%   | Resultados consistentes, mas menos robusto |
| T+1    | Ensemble (XGB + LGBM + RF)    | 63.33%   | 47.62%   | Robusto, mas abaixo dos modelos isolados   |
| T+2    | LightGBM (sem otimiza√ß√£o)     | 63.33%   | 52.17%   | Boa estabilidade em janelas futuras        |
| T+5    | LightGBM (sem otimiza√ß√£o)     | **76.67%** | 56.41% | Superou a meta de acur√°cia de 75%          |

---

## Avalia√ß√£o de Modelos Prophet e LSTM

| Modelo   | Acur√°cia | F1 (macro) | Observa√ß√µes                                      |
|----------|----------|------------|--------------------------------------------------|
| Prophet  | 56.67%   | 55.56%     | Convers√£o por varia√ß√£o percentual (classe 0/1)   |
| LSTM     | 53.33%   | 52.17%     | Modelo binarizado com base na varia√ß√£o di√°ria    |

---

## Estrat√©gias Adotadas

- **Valida√ß√£o temporal** com `TimeSeriesSplit`
- **RandomizedSearchCV** para otimiza√ß√£o de hiperpar√¢metros
- **Ajuste de thresholds (cutoff)** para maximizar o F1-score
- **Target multiclasse** com varia√ß√£o m√≠nima de ¬±0.5%
- **Testes com janelas m√≥veis** (2, 5, 10, 15, 20 e 25 anos de hist√≥rico)
- **Ensembles e Stacking** com compara√ß√µes detalhadas

---

## Conclus√µes

- O modelo **Random Forest simples**, com features b√°sicas e janela completa (1993‚Äì2025), superou abordagens mais complexas.
- Modelos baseados em √°rvore (RF, LGBM, XGB) tiveram melhor desempenho em geral.
- **Otimiza√ß√µes e ajustes de cutoff** aumentaram a sensibilidade em targets mais desafiadores.
- A complexidade n√£o garantiu ganho de performance ‚Äî a simplicidade venceu neste caso.
- Estrat√©gias como target multiclasse e uso de indicadores t√©cnicos trouxeram bons insights, mas os modelos bin√°rios com T+1 e T+2 foram os mais eficientes.

---

## Autora

**Carol Defavori**  
Analista de Dados | Cientista de Dados ‚Ä¢ P√≥s-Tech FIAP ‚Äì Data Analytics  
[LinkedIn](https://www.linkedin.com/in/caroldefavori) ‚Ä¢ [GitHub](https://github.com/caroldefavori)

---

## Requisitos T√©cnicos

- Python 3.10+
- Jupyter Notebook ou JupyterLab
- Ambiente virtual com `venv`, `conda` ou `poetry`

Instale as depend√™ncias com:

```bash
pip install -r requirements.txt
```

> Algumas bibliotecas, como `xgboost`, `lightgbm`, `prophet` e `tensorflow`, podem requerer compiladores ou ambientes espec√≠ficos.

---

## Reprodutibilidade

- Dados obtidos via `yfinance` com corte em **31/07/2025**
- Separa√ß√£o treino/teste com base em data (√∫ltimos 30 dias s√£o teste)
- Sementes fixas e valida√ß√£o temporal garantem estabilidade
- C√≥digo modular, comentado e execut√°vel de ponta a ponta
